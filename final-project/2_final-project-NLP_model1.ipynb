{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "provenance dataset train : https://github.com/gamebusterz/French-Sentiment-Analysis-Dataset (√©chantillon 300.000, origin = './nlp/tweets.csv' (concatenate=cat x* > tweets.csv))\n",
    "methodo :\n",
    "    1. train √† partir du dataset French sentiment analysis\n",
    "    2. cleanin : cleaning, token, stop-words puis s√©paration en train/test\n",
    "    3. Count vectorization\n",
    "    4. D√©v mod√®le de classification NLP (xgboost, logreg, naive bayes)\n",
    "    5. scraping twitter des tweets contenant un # entre 2 dates\n",
    "    6. Classification des tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time0 = datetime.now()\n",
    "import spacy\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 :  ML model construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>statutnull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Un avertissement juste: en raison de ce refus obstin√© d'envisager des exemptions sans but lucratif, nous devons ne pas suivre ceux qui ne nous suivent pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>merci!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>R√©ussi √† √©crire quelque chose en valeur! Au lit maintenant. J'esp√®re que les musiques resteront ou bien, je pourrais pleurer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>En allant √† kroger puis √† la piscine. Attendant un th√© √† mcdon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c'est g√©nial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  polarity  \\\n",
       "0  0         \n",
       "1  4         \n",
       "2  0         \n",
       "3  4         \n",
       "4  4         \n",
       "\n",
       "                                                                                                                                                    statutnull  \n",
       "0  Un avertissement juste: en raison de ce refus obstin√© d'envisager des exemptions sans but lucratif, nous devons ne pas suivre ceux qui ne nous suivent pas.  \n",
       "1  merci!                                                                                                                                                       \n",
       "2  R√©ussi √† √©crire quelque chose en valeur! Au lit maintenant. J'esp√®re que les musiques resteront ou bien, je pourrais pleurer.                                \n",
       "3  En allant √† kroger puis √† la piscine. Attendant un th√© √† mcdon.                                                                                              \n",
       "4  c'est g√©nial                                                                                                                                                 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('tweets.csv',index_col=[0]).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>statutnull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>- Awww, c'est nul. Tu aurais du prendre David Carr de Third Day. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Est contrari√© qu'il ne puisse pas mettre √† jour son facebook par sms... et pleurera peut-√™tre √† la fin, l'√©cole aujourd'hui aussi. Beurk!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>J'ai plong√© plusieurs fois pour la balle. A r√©ussi √† en sauver 50% le reste sort de limites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Tout mon corps a des d√©mangeaisons et comme si c'√©tait en feu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Non, il ne se comporte pas bien du tout. je suis en col√®re. pourquoi suis-je ici? Parce que je ne peux pas vous voir partout.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  polarity  \\\n",
       "0  0         \n",
       "1  0         \n",
       "2  0         \n",
       "3  0         \n",
       "4  0         \n",
       "\n",
       "                                                                                                                                  statutnull  \n",
       "0  - Awww, c'est nul. Tu aurais du prendre David Carr de Third Day. ;D                                                                        \n",
       "1  Est contrari√© qu'il ne puisse pas mettre √† jour son facebook par sms... et pleurera peut-√™tre √† la fin, l'√©cole aujourd'hui aussi. Beurk!  \n",
       "2  J'ai plong√© plusieurs fois pour la balle. A r√©ussi √† en sauver 50% le reste sort de limites                                                \n",
       "3  Tout mon corps a des d√©mangeaisons et comme si c'√©tait en feu                                                                              \n",
       "4  Non, il ne se comporte pas bien du tout. je suis en col√®re. pourquoi suis-je ici? Parce que je ne peux pas vous voir partout.              "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['polarity', 'statutnull'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = train.dropna()\n",
    "train['polarity'] = train['polarity'].str.replace(\"0\",\"negatif\").str.replace(\"4\",\"positif\")\n",
    "index_zero = train[(train['polarity'] != 'positif') & (train['polarity']!= 'negatif')].index\n",
    "train.drop(index_zero, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negatif    149741\n",
       "positif    149615\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['polarity'].value_counts()\n",
    "#.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(tweet):\n",
    "    tweet = re.sub(r'http\\S+|(pic.twitter\\.[^\\s]+)|(www\\.[^\\s]+)|(@\\S+)|\\s\\s+|[^\\w\\s]',' ',tweet) \n",
    "    #1:http+suite/2.pic.twitter+suite/3.www.+suite/4.@+suite/5.espaces++/6.ponctuation\n",
    "    tweet = tweet.lower().strip() #bdc\n",
    "    tweet = word_tokenize(tweet) #tokenisation\n",
    "    stop_words = stopwords.words('french') #stopwords nltk\n",
    "    stop_words.append('rt') #+'rt'\n",
    "    tweet = [word for word in tweet if word not in stop_words]\n",
    "    tweet = [word for word in tweet if len(word)>1] #exclus mot de 1 lettre\n",
    "    return ' '.join(tweet) #retour sans tokenisation, requis par spacy\n",
    "def stem_spacy(tweet):\n",
    "    import spacy\n",
    "    nlp = spacy.load('fr_core_news_sm')\n",
    "    tweet = tweet.apply(nlp)\n",
    "    tweet_stem=[]\n",
    "    for doc in tweet:\n",
    "        tweet_stem.append([word.lemma_ for word in doc])\n",
    "    return tweet_stem"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nouvelle colonne avec tweet nettoy√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>original</th>\n",
       "      <th>tweet_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>206130</td>\n",
       "      <td>negatif</td>\n",
       "      <td>stress√© mal t√™te stress√©</td>\n",
       "      <td>Stress√© ... mal √† la t√™te ... stress√©</td>\n",
       "      <td>[stresser, mal, t√™te, stresser]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227455</td>\n",
       "      <td>negatif</td>\n",
       "      <td>claire manque action</td>\n",
       "      <td>Et claire manque en action</td>\n",
       "      <td>[clair, manquer, action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4963</td>\n",
       "      <td>negatif</td>\n",
       "      <td>neige avril ugh parfois d√©teste pittsburgh manque</td>\n",
       "      <td>Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la</td>\n",
       "      <td>[neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930119</td>\n",
       "      <td>positif</td>\n",
       "      <td>dernier jour lyc√©e enfin</td>\n",
       "      <td>Dernier jour de lyc√©e? enfin</td>\n",
       "      <td>[dernier, jour, lyc√©e, enfin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270680</td>\n",
       "      <td>negatif</td>\n",
       "      <td>nettoyer emballer affaires veux partir ici demain</td>\n",
       "      <td>Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain</td>\n",
       "      <td>[nettoyer, emballer, affairer, vouloir, partir, ici, demain]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                              tweet  \\\n",
       "206130  negatif  stress√© mal t√™te stress√©                            \n",
       "227455  negatif  claire manque action                                \n",
       "4963    negatif  neige avril ugh parfois d√©teste pittsburgh manque   \n",
       "930119  positif  dernier jour lyc√©e enfin                            \n",
       "270680  negatif  nettoyer emballer affaires veux partir ici demain   \n",
       "\n",
       "                                                                          original  \\\n",
       "206130  Stress√© ... mal √† la t√™te ... stress√©                                        \n",
       "227455  Et claire manque en action                                                   \n",
       "4963    Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la   \n",
       "930119  Dernier jour de lyc√©e? enfin                                                 \n",
       "270680  Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain       \n",
       "\n",
       "                                                          tweet_stem  \n",
       "206130  [stresser, mal, t√™te, stresser]                               \n",
       "227455  [clair, manquer, action]                                      \n",
       "4963    [neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]  \n",
       "930119  [dernier, jour, lyc√©e, enfin]                                 \n",
       "270680  [nettoyer, emballer, affairer, vouloir, partir, ici, demain]  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.statutnull = train.statutnull.astype(str)\n",
    "train['original'] = train['statutnull']\n",
    "train.statutnull = train.statutnull.apply(lambda s: clean_up(s))\n",
    "train['tweet_stem'] = stem_spacy(train.statutnull)\n",
    "train.rename(columns={'statutnull':'tweet'},inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299356, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>original</th>\n",
       "      <th>tweet_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negatif</td>\n",
       "      <td>stress√© mal t√™te stress√©</td>\n",
       "      <td>Stress√© ... mal √† la t√™te ... stress√©</td>\n",
       "      <td>[stresser, mal, t√™te, stresser]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negatif</td>\n",
       "      <td>claire manque action</td>\n",
       "      <td>Et claire manque en action</td>\n",
       "      <td>[clair, manquer, action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negatif</td>\n",
       "      <td>neige avril ugh parfois d√©teste pittsburgh manque</td>\n",
       "      <td>Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la</td>\n",
       "      <td>[neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>positif</td>\n",
       "      <td>dernier jour lyc√©e enfin</td>\n",
       "      <td>Dernier jour de lyc√©e? enfin</td>\n",
       "      <td>[dernier, jour, lyc√©e, enfin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negatif</td>\n",
       "      <td>nettoyer emballer affaires veux partir ici demain</td>\n",
       "      <td>Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain</td>\n",
       "      <td>[nettoyer, emballer, affairer, vouloir, partir, ici, demain]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  polarity                                              tweet  \\\n",
       "0  negatif  stress√© mal t√™te stress√©                            \n",
       "1  negatif  claire manque action                                \n",
       "2  negatif  neige avril ugh parfois d√©teste pittsburgh manque   \n",
       "3  positif  dernier jour lyc√©e enfin                            \n",
       "4  negatif  nettoyer emballer affaires veux partir ici demain   \n",
       "\n",
       "                                                                     original  \\\n",
       "0  Stress√© ... mal √† la t√™te ... stress√©                                        \n",
       "1  Et claire manque en action                                                   \n",
       "2  Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la   \n",
       "3  Dernier jour de lyc√©e? enfin                                                 \n",
       "4  Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain       \n",
       "\n",
       "                                                     tweet_stem  \n",
       "0  [stresser, mal, t√™te, stresser]                               \n",
       "1  [clair, manquer, action]                                      \n",
       "2  [neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]  \n",
       "3  [dernier, jour, lyc√©e, enfin]                                 \n",
       "4  [nettoyer, emballer, affairer, vouloir, partir, ici, demain]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nouvelle colonne pour utilisation ML Xgboost et R√©gression lin√©aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>original</th>\n",
       "      <th>tweet_stem</th>\n",
       "      <th>tweet_stem_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>206130</td>\n",
       "      <td>negatif</td>\n",
       "      <td>stress√© mal t√™te stress√©</td>\n",
       "      <td>Stress√© ... mal √† la t√™te ... stress√©</td>\n",
       "      <td>[stresser, mal, t√™te, stresser]</td>\n",
       "      <td>stresser mal t√™te stresser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227455</td>\n",
       "      <td>negatif</td>\n",
       "      <td>claire manque action</td>\n",
       "      <td>Et claire manque en action</td>\n",
       "      <td>[clair, manquer, action]</td>\n",
       "      <td>clair manquer action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4963</td>\n",
       "      <td>negatif</td>\n",
       "      <td>neige avril ugh parfois d√©teste pittsburgh manque</td>\n",
       "      <td>Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la</td>\n",
       "      <td>[neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]</td>\n",
       "      <td>neiger avril ugh parfois d√©tester pittsburgh manquer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930119</td>\n",
       "      <td>positif</td>\n",
       "      <td>dernier jour lyc√©e enfin</td>\n",
       "      <td>Dernier jour de lyc√©e? enfin</td>\n",
       "      <td>[dernier, jour, lyc√©e, enfin]</td>\n",
       "      <td>dernier jour lyc√©e enfin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270680</td>\n",
       "      <td>negatif</td>\n",
       "      <td>nettoyer emballer affaires veux partir ici demain</td>\n",
       "      <td>Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain</td>\n",
       "      <td>[nettoyer, emballer, affairer, vouloir, partir, ici, demain]</td>\n",
       "      <td>nettoyer emballer affairer vouloir partir ici demain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       polarity                                              tweet  \\\n",
       "206130  negatif  stress√© mal t√™te stress√©                            \n",
       "227455  negatif  claire manque action                                \n",
       "4963    negatif  neige avril ugh parfois d√©teste pittsburgh manque   \n",
       "930119  positif  dernier jour lyc√©e enfin                            \n",
       "270680  negatif  nettoyer emballer affaires veux partir ici demain   \n",
       "\n",
       "                                                                          original  \\\n",
       "206130  Stress√© ... mal √† la t√™te ... stress√©                                        \n",
       "227455  Et claire manque en action                                                   \n",
       "4963    Il neige ... en avril. Ugh, parfois je d√©teste pittsburgh. Je me manque la   \n",
       "930119  Dernier jour de lyc√©e? enfin                                                 \n",
       "270680  Nettoyer et emballer mes affaires ... je ne veux pas partir ici demain       \n",
       "\n",
       "                                                          tweet_stem  \\\n",
       "206130  [stresser, mal, t√™te, stresser]                                \n",
       "227455  [clair, manquer, action]                                       \n",
       "4963    [neiger, avril, ugh, parfois, d√©tester, pittsburgh, manquer]   \n",
       "930119  [dernier, jour, lyc√©e, enfin]                                  \n",
       "270680  [nettoyer, emballer, affairer, vouloir, partir, ici, demain]   \n",
       "\n",
       "                                             tweet_stem_join  \n",
       "206130  stresser mal t√™te stresser                            \n",
       "227455  clair manquer action                                  \n",
       "4963    neiger avril ugh parfois d√©tester pittsburgh manquer  \n",
       "930119  dernier jour lyc√©e enfin                              \n",
       "270680  nettoyer emballer affairer vouloir partir ici demain  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet_stem_join'] = train.tweet_stem.apply(lambda x: ' '.join(x)).astype(str)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Vectorisation des mots avec Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word') \n",
    "cv = count_vectorizer.fit(train['tweet_stem_join'])\n",
    "pickle.dump(cv, open(\"cv1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299356, 79161)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ = count_vectorizer.fit_transform(train['tweet_stem_join'])\n",
    "cv_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299356, 79161)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1 = pickle.load(open(\"cv1.pkl\", 'rb'))\n",
    "cv1_new = CountVectorizer(vocabulary = cv1.vocabulary_)\n",
    "X_cv1 = cv1_new.transform(train['tweet_stem_join'])\n",
    "X_cv1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OU vectorisation avec tfidf module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.7, stop_words=stopwords.words('french'))  \n",
    "X = tfidfconverter.fit_transform(train['tweet_stem_join']).toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,train['polarity'] , test_size=.2,\n",
    "                                                 stratify=train['polarity'], random_state=42)\n",
    "# moins bon score tfidf car corpus peu vari√© (cause traduction ?)\n",
    "# https://datascience.stackexchange.com/questions/49047/will-a-count-vectorizer-ever-perform-slightly-better-than-tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps import et clean: 1:42:17.555866\n"
     ]
    }
   ],
   "source": [
    "end_time0 = datetime.now()\n",
    "print('Temps import et clean: {}'.format(end_time0 - start_time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - √† faire"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_time_svc = datetime.now()\n",
    "X_train_svc,X_test_svc,y_train_svc,y_test_svc = train_test_split(cv_,train['polarity'],test_size=.2,\n",
    "                                                 stratify=train['polarity'], random_state=42)\n",
    "grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "svc = SVC()\n",
    "svc_wv=GridSearchCV(svc,grid,cv=10)\n",
    "svc_wv.fit(X_train_svc,y_train_svc)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",svc_wv.best_params_)\n",
    "print(\"accuracy :\",svc_wv.best_score_)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_svc,y_train_svc)\n",
    "prediction_svc = svc.predict(X_test_svc)\n",
    "print(classification_report(prediction_svc,y_test_svc))\n",
    "end_time_svc = datetime.now()\n",
    "print('Temps mod√®le SVM : {}'.format(end_time_svc - start_time_svc))\n",
    "#Accuracy 0,50\n",
    "#Temps mod√®le SVM : 3:50:10.268178"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model - non retenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time1 = datetime.now()\n",
    "X_train_xg,X_test_xg,y_train_xg,y_test_xg = train_test_split(cv_,train['polarity'],test_size=.2,stratify=train['polarity'], random_state=42)\n",
    "#grid search xgb\n",
    "#grid={\"max_depth\":[3,6,9],'min_child_weight':[4,5,6]}\n",
    "#xgbc = XGBClassifier(n_estimators=1000, nthread=6, objective= 'binary:logistic')\n",
    "#xgbc_cv=GridSearchCV(xgbc,grid,cv=10)\n",
    "#xgbc_cv.fit(X_train_xg,y_train_xg)\n",
    "#print(\"tuned hpyerparameters :(best parameters) \",xgbc_cv.best_params_)\n",
    "#print(\"accuracy :\",xgbc_cv.best_score_)\n",
    "#tuned hpyerparameters :(best parameters)  {'max_depth': 9, 'min_child_weight': 4}\n",
    "#accuracy : 0.7395625\n",
    "#model\n",
    "xgbc = XGBClassifier(max_depth=9, min_child_weight=4, n_estimators=1000, nthread= 3)\n",
    "xgbc.fit(X_train_xg,y_train_xg)\n",
    "prediction_xgb = xgbc.predict(X_test_xg)\n",
    "print(classification_report(prediction_xgb,y_test_xg))\n",
    "#0.742425 count vectorizer (max_depth=6, n_estimators=1000, nthread= 3)\n",
    "#0.7415 tfidf\n",
    "print(accuracy_score(prediction_xgb,y_test_xg))\n",
    "#0.7531 300.000 sample 21/01\n",
    "end_time1 = datetime.now()\n",
    "print('Temps mod√®le XGBoost : {}'.format(end_time1 - start_time1))\n",
    "#Temps mod√®le XGBoost : 0:10:54.389062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model - retenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time2 = datetime.now()\n",
    "X_train_logreg,X_test_logreg,y_train_logreg,y_test_logreg = train_test_split(cv_,train['polarity'] , test_size=.2,\n",
    "                                                 stratify=train['polarity'], random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "cv_logreg=GridSearchCV(logreg,grid,cv=10)\n",
    "cv_logreg.fit(X_train_logreg,y_train_logreg)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",cv_logreg.best_params_)\n",
    "print(\"accuracy :\",cv_logreg.best_score_)\n",
    "#tuned hpyerparameters :(best parameters)  {'C': 0.1, 'penalty': 'l2'}\n",
    "#accuracy : 0.7391625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aline\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.73      0.76      0.74     28893\n",
      "     positif       0.77      0.74      0.75     30979\n",
      "\n",
      "    accuracy                           0.75     59872\n",
      "   macro avg       0.75      0.75      0.75     59872\n",
      "weighted avg       0.75      0.75      0.75     59872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1,penalty=\"l2\")\n",
    "logreg.fit(X_train_logreg,y_train_logreg)\n",
    "prediction_logreg = logreg.predict(X_test_logreg)\n",
    "print(classification_report(prediction_logreg,y_test_logreg))\n",
    "#0.7628 count vectorizer\n",
    "#0.74105 tfidf\n",
    "print(accuracy_score(prediction_logreg,y_test_logreg))\n",
    "end_time2 = datetime.now()\n",
    "print('Temps mod√®le Logistic regression: {}'.format(end_time2 - start_time2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model - non retenu"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train2 = train.sample(100000)\n",
    "start_time3 = datetime.now()\n",
    "all_words = []\n",
    "NUM_FEATURES = 5000\n",
    "for index, value in train2.tweet.iteritems():\n",
    "    if value not in all_words:\n",
    "        all_words += value\n",
    "top_features = [x[0] for x in nltk.FreqDist(all_words).most_common(NUM_FEATURES)]\n",
    "df=pd.DataFrame.from_dict(nltk.FreqDist(all_words),orient='index')\n",
    "df.sort_values(by=0, ascending=False).reset_index().head(10)\n",
    "def build_features(words):\n",
    "    features = {}\n",
    "    for w in top_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "featuresets = []\n",
    "for index, row in train.iterrows():\n",
    "    featuresets.append((build_features(row['tweet']), row['polarity']))\n",
    "print(featuresets[:2])\n",
    "train_set, test = train_test_split(featuresets, test_size=0.2)\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(classifier.show_most_informative_features(n=10))\n",
    "print(nltk.classify.accuracy(classifier, test))\n",
    "# score 73,56% pour sample 100.000 avec stem nltk\n",
    "# score 73,88% avec sample 100.000 avec stem spacy \n",
    "print(classification_report(classifier, test))\n",
    "end_time3 = datetime.now()\n",
    "print('Temps mod√®le Naive Bayes: {}'.format(end_time3 - start_time3))\n",
    "print('Classifying with Naive Bayes in progress...')\n",
    "for i in range(len(train_sample)):\n",
    "    train_sample['polarity_NB'].iloc[i] = classifier.classify(dict([token,True] for token in train_sample['tweet_processed2'].iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : applying final model on greve_twitter extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_processed</th>\n",
       "      <th>tweet_processed2</th>\n",
       "      <th>polarity2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negatif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comment les travailleurs belges ont bloqu√© la #RetraiteParPoints #FiersDeLaGreve #reformedesretraites . #GiletsJaunes #greve31decembre #cgt #fo #sudrail #France #Belgique #BFMTV #lci #cnews</td>\n",
       "      <td>comment travailleurs belges bloqu√© retraiteparpoints fiersdelagreve reformedesretraites giletsjaunes greve31decembre cgt fo sudrail france belgique bfmtv lci cnews</td>\n",
       "      <td>comment travailleur belge bloquer retraiteparpoints fiersdelagreve reformedesretraites giletsjaunes greve31decembre cgt fo sudrail france belgique bfmtv lci cnews</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negatif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Retraites #ReformeRetraites #reformedesretraites #Macron #GiletsJaunes #greve31decembre #CGT #EdouardPhilippe #SNCF #RATP #FiersDeLaGreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø de #Greve contre la R√©forme...</td>\n",
       "      <td>retraites reformeretraites reformedesretraites macron giletsjaunes greve31decembre cgt edouardphilippe sncf ratp fiersdelagreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø greve contre r√©forme</td>\n",
       "      <td>retraiter reformeretraites reformedesretraites macron giletsjaunes greve31decembre cgt edouardphilippe sncf ratp fiersdelagreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø greve contrer r√©former</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negatif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#R√©formedesretraites : le ton monte entre le ‚Å¶@gouvernementFR‚Å© et la #CGT - Le Parisien</td>\n",
       "      <td>r√©formedesretraites monte entre cgt parisien</td>\n",
       "      <td>r√©formedesretraites monter entrer cgt parisien</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negatif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apparemment √ßa d√©range beaucoup ! ! #France #greve31decembre #reformedesretraites #GiletsJaunes #Coulommiers #√©cologie https://twitter.com/franck77120/status/1211370152933167105</td>\n",
       "      <td>apparemment √ßa d√©range beaucoup france greve31decembre reformedesretraites giletsjaunes coulommiers √©cologie</td>\n",
       "      <td>apparemment √ßa d√©ranger beaucoup france greve31decembre reformedesretraites giletsjaunes coulommiers √©cologie</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negatif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tout √† fait, un stress permanent qui se rajoutera √† celui du travail, de la recherche d'un emploi, de la perte d'un emploi #reformedesretraites #RetraiteParPoints .</td>\n",
       "      <td>tout fait stress permanent rajoutera celui travail recherche emploi perte emploi reformedesretraites retraiteparpoints</td>\n",
       "      <td>tout faire stress permanent rajouter celui travail rechercher emploi perte emploi reformedesretraites retraiteparpoints</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  polarity  date  \\\n",
       "0  negatif NaN     \n",
       "1  negatif NaN     \n",
       "2  negatif NaN     \n",
       "3  negatif NaN     \n",
       "4  negatif NaN     \n",
       "\n",
       "                                                                                                                                                                                           tweet  \\\n",
       "0  Comment les travailleurs belges ont bloqu√© la #RetraiteParPoints #FiersDeLaGreve #reformedesretraites . #GiletsJaunes #greve31decembre #cgt #fo #sudrail #France #Belgique #BFMTV #lci #cnews   \n",
       "1  #Retraites #ReformeRetraites #reformedesretraites #Macron #GiletsJaunes #greve31decembre #CGT #EdouardPhilippe #SNCF #RATP #FiersDeLaGreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø de #Greve contre la R√©forme...           \n",
       "2  #R√©formedesretraites : le ton monte entre le ‚Å¶@gouvernementFR‚Å© et la #CGT - Le Parisien                                                                                                         \n",
       "3  Apparemment √ßa d√©range beaucoup ! ! #France #greve31decembre #reformedesretraites #GiletsJaunes #Coulommiers #√©cologie https://twitter.com/franck77120/status/1211370152933167105               \n",
       "4  Tout √† fait, un stress permanent qui se rajoutera √† celui du travail, de la recherche d'un emploi, de la perte d'un emploi #reformedesretraites #RetraiteParPoints .                            \n",
       "\n",
       "                                                                                                                                                       tweet_processed  \\\n",
       "0  comment travailleurs belges bloqu√© retraiteparpoints fiersdelagreve reformedesretraites giletsjaunes greve31decembre cgt fo sudrail france belgique bfmtv lci cnews   \n",
       "1  retraites reformeretraites reformedesretraites macron giletsjaunes greve31decembre cgt edouardphilippe sncf ratp fiersdelagreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø greve contre r√©forme      \n",
       "2  r√©formedesretraites monte entre cgt parisien                                                                                                                          \n",
       "3  apparemment √ßa d√©range beaucoup france greve31decembre reformedesretraites giletsjaunes coulommiers √©cologie                                                          \n",
       "4  tout fait stress permanent rajoutera celui travail recherche emploi perte emploi reformedesretraites retraiteparpoints                                                \n",
       "\n",
       "                                                                                                                                                     tweet_processed2  \\\n",
       "0  comment travailleur belge bloquer retraiteparpoints fiersdelagreve reformedesretraites giletsjaunes greve31decembre cgt fo sudrail france belgique bfmtv lci cnews   \n",
       "1  retraiter reformeretraites reformedesretraites macron giletsjaunes greve31decembre cgt edouardphilippe sncf ratp fiersdelagreve ùüÆùü≥ ùó≤ùó∫ùó≤ ùó∑ùóºùòÇùóø greve contrer r√©former   \n",
       "2  r√©formedesretraites monter entrer cgt parisien                                                                                                                       \n",
       "3  apparemment √ßa d√©ranger beaucoup france greve31decembre reformedesretraites giletsjaunes coulommiers √©cologie                                                        \n",
       "4  tout faire stress permanent rajouter celui travail rechercher emploi perte emploi reformedesretraites retraiteparpoints                                              \n",
       "\n",
       "  polarity2  \n",
       "0  negatif   \n",
       "1  negatif   \n",
       "2  negatif   \n",
       "3  negatif   \n",
       "4  negatif   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greve_twitter=pd.read_csv('greve_twitter_final.csv',index_col=[0])\n",
    "greve_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv2 = cv1_new.transform(greve_twitter['tweet_processed2'])\n",
    "greve_twitter['polarity']=logreg.predict(X_cv2)\n",
    "greve_twitter.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
